{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43e525ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\srich\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\srich\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\srich\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\srich\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\srich\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\srich\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d901cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\srich\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\srich\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\srich\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading NLTK\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0e06aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "text=\"\"\"I have a rendezvous with Death, At some disputed barricade.When Spring comes back with rustling shade, And apple blossoms fill coming the air. “I have a rendezvous with Death” When Spring brings back blue days came and fair. And I have learned too to laugh with only my teeth and shake hands without my heart. I have also learned to say, ’Goodbye’,when I mean ‘Good-riddance’:to say ‘Glad to meet you’, without being glad; and to say ‘It’s been nice talking to you’, after being bored.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbb9ccee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I have a rendezvous with Death, At some disputed barricade.When Spring comes back with rustling shade, And apple blossoms fill coming the air.', '“I have a rendezvous with Death” When Spring brings back blue days came and fair.', 'And I have learned too to laugh with only my teeth and shake hands without my heart.', 'I have also learned to say, ’Goodbye’,when I mean ‘Good-riddance’:to say ‘Glad to meet you’, without being glad; and to say ‘It’s been nice talking to you’, after being bored.']\n"
     ]
    }
   ],
   "source": [
    "tokenized_text=sent_tokenize(text)\n",
    "print(tokenized_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7088f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'have', 'a', 'rendezvous', 'with', 'Death', ',', 'At', 'some', 'disputed', 'barricade.When', 'Spring', 'comes', 'back', 'with', 'rustling', 'shade', ',', 'And', 'apple', 'blossoms', 'fill', 'coming', 'the', 'air', '.', '“', 'I', 'have', 'a', 'rendezvous', 'with', 'Death', '”', 'When', 'Spring', 'brings', 'back', 'blue', 'days', 'came', 'and', 'fair', '.', 'And', 'I', 'have', 'learned', 'too', 'to', 'laugh', 'with', 'only', 'my', 'teeth', 'and', 'shake', 'hands', 'without', 'my', 'heart', '.', 'I', 'have', 'also', 'learned', 'to', 'say', ',', '’', 'Goodbye', '’', ',', 'when', 'I', 'mean', '‘', 'Good-riddance', '’', ':', 'to', 'say', '‘', 'Glad', 'to', 'meet', 'you', '’', ',', 'without', 'being', 'glad', ';', 'and', 'to', 'say', '‘', 'It', '’', 's', 'been', 'nice', 'talking', 'to', 'you', '’', ',', 'after', 'being', 'bored', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokenized_word=word_tokenize(text)\n",
    "print(tokenized_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9275be3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 66 samples and 111 outcomes>\n"
     ]
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist(tokenized_word)\n",
    "print(fdist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84a41451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 6), ('to', 6)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist.most_common(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f69c18be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"weren't\", 'this', 'under', 'wasn', 'at', \"shouldn't\", 'how', \"hasn't\", 'other', 'who', 'that', 'their', 'couldn', \"haven't\", 'y', \"she's\", 'hers', 'its', 'below', 'over', 'few', 'he', 'were', 'about', 'there', \"don't\", 'down', 'off', 'm', 'out', 'theirs', 'before', 'so', 'because', 'i', 'me', 'those', \"shan't\", 'yourselves', 'through', 'should', 'is', 'up', \"you've\", 'can', 'does', 'ourselves', 'nor', 'these', \"isn't\", 'yourself', 'ma', 'if', 'between', 'same', 'some', 'o', 'in', 'don', 'themselves', 'have', 'will', 'she', 'or', 'aren', 'here', 'such', 'shouldn', 'our', 'did', 'being', 'just', \"wasn't\", 'while', 'was', 'd', 'not', \"you'd\", 'but', 's', 'then', 'against', \"hadn't\", 'herself', 'all', \"doesn't\", 'it', 'whom', 'which', 'from', 'for', \"aren't\", 'most', 'am', 'shan', 'didn', \"needn't\", 'they', 'doing', 'again', 'his', 'an', 'himself', 'than', \"you're\", 'mustn', 'itself', 'we', 'the', 'to', \"should've\", 'own', 'won', 're', 'very', 'my', 'both', \"mightn't\", 'are', 'has', 'why', 'on', 'where', \"mustn't\", 'mightn', 'as', 'hasn', \"you'll\", 'during', 'more', 'each', \"won't\", 'once', 'after', 'you', 'needn', \"wouldn't\", 'no', 'what', 'further', 'isn', 'above', 'wouldn', 'do', 'with', 'of', 'll', \"it's\", 'and', 'your', 'by', 'ain', 'been', 'doesn', 'into', \"that'll\", 'ours', 'weren', 'him', 'myself', 'yours', 'any', 'when', 'too', 'only', 've', \"couldn't\", 'until', 'be', 'hadn', 'having', 'haven', 't', 'them', 'a', 'now', 'had', \"didn't\", 'her'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "print(stop_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a882f1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Sentence: ['I', 'have', 'a', 'rendezvous', 'with', 'Death', ',', 'At', 'some', 'disputed', 'barricade.When', 'Spring', 'comes', 'back', 'with', 'rustling', 'shade', ',', 'And', 'apple', 'blossoms', 'fill', 'coming', 'the', 'air', '.', '“', 'I', 'have', 'a', 'rendezvous', 'with', 'Death', '”', 'When', 'Spring', 'brings', 'back', 'blue', 'days', 'came', 'and', 'fair', '.', 'And', 'I', 'have', 'learned', 'too', 'to', 'laugh', 'with', 'only', 'my', 'teeth', 'and', 'shake', 'hands', 'without', 'my', 'heart', '.', 'I', 'have', 'also', 'learned', 'to', 'say', ',', '’', 'Goodbye', '’', ',', 'when', 'I', 'mean', '‘', 'Good-riddance', '’', ':', 'to', 'say', '‘', 'Glad', 'to', 'meet', 'you', '’', ',', 'without', 'being', 'glad', ';', 'and', 'to', 'say', '‘', 'It', '’', 's', 'been', 'nice', 'talking', 'to', 'you', '’', ',', 'after', 'being', 'bored', '.']\n",
      "\n",
      "\n",
      "Filterd Sentence: ['I', 'rendezvous', 'Death', ',', 'At', 'disputed', 'barricade.When', 'Spring', 'comes', 'back', 'rustling', 'shade', ',', 'And', 'apple', 'blossoms', 'fill', 'coming', 'air', '.', '“', 'I', 'rendezvous', 'Death', '”', 'When', 'Spring', 'brings', 'back', 'blue', 'days', 'came', 'fair', '.', 'And', 'I', 'learned', 'laugh', 'teeth', 'shake', 'hands', 'without', 'heart', '.', 'I', 'also', 'learned', 'say', ',', '’', 'Goodbye', '’', ',', 'I', 'mean', '‘', 'Good-riddance', '’', ':', 'say', '‘', 'Glad', 'meet', '’', ',', 'without', 'glad', ';', 'say', '‘', 'It', '’', 'nice', 'talking', '’', ',', 'bored', '.']\n"
     ]
    }
   ],
   "source": [
    "filtered_sent=[]\n",
    "for w in tokenized_word:\n",
    "    if w not in stop_words:\n",
    "        filtered_sent.append(w)\n",
    "print(\"Tokenized Sentence:\",tokenized_word)\n",
    "print(\"\\n\")\n",
    "print(\"Filterd Sentence:\",filtered_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f86095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f78c604",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15ee2a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Sentence: ['I', 'rendezvous', 'Death', ',', 'At', 'disputed', 'barricade.When', 'Spring', 'comes', 'back', 'rustling', 'shade', ',', 'And', 'apple', 'blossoms', 'fill', 'coming', 'air', '.', '“', 'I', 'rendezvous', 'Death', '”', 'When', 'Spring', 'brings', 'back', 'blue', 'days', 'came', 'fair', '.', 'And', 'I', 'learned', 'laugh', 'teeth', 'shake', 'hands', 'without', 'heart', '.', 'I', 'also', 'learned', 'say', ',', '’', 'Goodbye', '’', ',', 'I', 'mean', '‘', 'Good-riddance', '’', ':', 'say', '‘', 'Glad', 'meet', '’', ',', 'without', 'glad', ';', 'say', '‘', 'It', '’', 'nice', 'talking', '’', ',', 'bored', '.']\n",
      "\n",
      "\n",
      "Stemmed Sentence: ['i', 'rendezv', 'death', ',', 'at', 'disput', 'barricade.when', 'spring', 'come', 'back', 'rustl', 'shade', ',', 'and', 'appl', 'blossom', 'fill', 'come', 'air', '.', '“', 'i', 'rendezv', 'death', '”', 'when', 'spring', 'bring', 'back', 'blue', 'day', 'came', 'fair', '.', 'and', 'i', 'learn', 'laugh', 'teeth', 'shake', 'hand', 'without', 'heart', '.', 'i', 'also', 'learn', 'say', ',', '’', 'goodby', '’', ',', 'i', 'mean', '‘', 'good-ridd', '’', ':', 'say', '‘', 'glad', 'meet', '’', ',', 'without', 'glad', ';', 'say', '‘', 'it', '’', 'nice', 'talk', '’', ',', 'bore', '.']\n"
     ]
    }
   ],
   "source": [
    "stemmed_words=[]\n",
    "for w in filtered_sent:\n",
    "    stemmed_words.append(ps.stem(w))\n",
    "print(\"Filtered Sentence:\",filtered_sent)\n",
    "print('\\n')\n",
    "print(\"Stemmed Sentence:\",stemmed_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f567f49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\srich\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Create WordNetLemmatizer object\n",
    "wnl = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "678e9dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ---> I\n",
      "rendezvous ---> rendezvous\n",
      "Death ---> Death\n",
      ", ---> ,\n",
      "At ---> At\n",
      "disputed ---> disputed\n",
      "barricade.When ---> barricade.When\n",
      "Spring ---> Spring\n",
      "comes ---> come\n",
      "back ---> back\n",
      "rustling ---> rustling\n",
      "shade ---> shade\n",
      ", ---> ,\n",
      "And ---> And\n",
      "apple ---> apple\n",
      "blossoms ---> blossom\n",
      "fill ---> fill\n",
      "coming ---> coming\n",
      "air ---> air\n",
      ". ---> .\n",
      "“ ---> “\n",
      "I ---> I\n",
      "rendezvous ---> rendezvous\n",
      "Death ---> Death\n",
      "” ---> ”\n",
      "When ---> When\n",
      "Spring ---> Spring\n",
      "brings ---> brings\n",
      "back ---> back\n",
      "blue ---> blue\n",
      "days ---> day\n",
      "came ---> came\n",
      "fair ---> fair\n",
      ". ---> .\n",
      "And ---> And\n",
      "I ---> I\n",
      "learned ---> learned\n",
      "laugh ---> laugh\n",
      "teeth ---> teeth\n",
      "shake ---> shake\n",
      "hands ---> hand\n",
      "without ---> without\n",
      "heart ---> heart\n",
      ". ---> .\n",
      "I ---> I\n",
      "also ---> also\n",
      "learned ---> learned\n",
      "say ---> say\n",
      ", ---> ,\n",
      "’ ---> ’\n",
      "Goodbye ---> Goodbye\n",
      "’ ---> ’\n",
      ", ---> ,\n",
      "I ---> I\n",
      "mean ---> mean\n",
      "‘ ---> ‘\n",
      "Good-riddance ---> Good-riddance\n",
      "’ ---> ’\n",
      ": ---> :\n",
      "say ---> say\n",
      "‘ ---> ‘\n",
      "Glad ---> Glad\n",
      "meet ---> meet\n",
      "’ ---> ’\n",
      ", ---> ,\n",
      "without ---> without\n",
      "glad ---> glad\n",
      "; ---> ;\n",
      "say ---> say\n",
      "‘ ---> ‘\n",
      "It ---> It\n",
      "’ ---> ’\n",
      "nice ---> nice\n",
      "talking ---> talking\n",
      "’ ---> ’\n",
      ", ---> ,\n",
      "bored ---> bored\n",
      ". ---> .\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# single word lemmatization examples\n",
    "wrd=[]\n",
    "for words in filtered_sent:\n",
    "    print(words + \" ---> \" + wnl.lemmatize(words))\n",
    "    wrd.append(wnl.lemmatize(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dd78bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\srich\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8595a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final=nltk.pos_tag(wrd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f48b49d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('rendezvous', 'VBP'),\n",
       " ('Death', 'NNP'),\n",
       " (',', ','),\n",
       " ('At', 'IN'),\n",
       " ('disputed', 'VBN'),\n",
       " ('barricade.When', 'NN'),\n",
       " ('Spring', 'NNP'),\n",
       " ('come', 'VBP'),\n",
       " ('back', 'RB'),\n",
       " ('rustling', 'VBG'),\n",
       " ('shade', 'NN'),\n",
       " (',', ','),\n",
       " ('And', 'CC'),\n",
       " ('apple', 'NN'),\n",
       " ('blossom', 'NN'),\n",
       " ('fill', 'NN'),\n",
       " ('coming', 'VBG'),\n",
       " ('air', 'NN'),\n",
       " ('.', '.'),\n",
       " ('“', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('rendezvous', 'VBP'),\n",
       " ('Death', 'NNP'),\n",
       " ('”', 'NN'),\n",
       " ('When', 'WRB'),\n",
       " ('Spring', 'NN'),\n",
       " ('brings', 'VBZ'),\n",
       " ('back', 'RB'),\n",
       " ('blue', 'JJ'),\n",
       " ('day', 'NN'),\n",
       " ('came', 'VBD'),\n",
       " ('fair', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('I', 'PRP'),\n",
       " ('learned', 'VBD'),\n",
       " ('laugh', 'IN'),\n",
       " ('teeth', 'NNS'),\n",
       " ('shake', 'VBP'),\n",
       " ('hand', 'NN'),\n",
       " ('without', 'IN'),\n",
       " ('heart', 'NN'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('also', 'RB'),\n",
       " ('learned', 'VBD'),\n",
       " ('say', 'UH'),\n",
       " (',', ','),\n",
       " ('’', 'JJ'),\n",
       " ('Goodbye', 'NNP'),\n",
       " ('’', 'NNP'),\n",
       " (',', ','),\n",
       " ('I', 'PRP'),\n",
       " ('mean', 'VBP'),\n",
       " ('‘', 'JJ'),\n",
       " ('Good-riddance', 'NNP'),\n",
       " ('’', 'NN'),\n",
       " (':', ':'),\n",
       " ('say', 'VB'),\n",
       " ('‘', 'NNP'),\n",
       " ('Glad', 'NNP'),\n",
       " ('meet', 'NN'),\n",
       " ('’', 'NNP'),\n",
       " (',', ','),\n",
       " ('without', 'IN'),\n",
       " ('glad', 'NN'),\n",
       " (';', ':'),\n",
       " ('say', 'VB'),\n",
       " ('‘', 'IN'),\n",
       " ('It', 'PRP'),\n",
       " ('’', 'NNP'),\n",
       " ('nice', 'JJ'),\n",
       " ('talking', 'VBG'),\n",
       " ('’', 'NN'),\n",
       " (',', ','),\n",
       " ('bored', 'VBD'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65ffbf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\srich\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping help\\tagsets.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3edcaddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('JJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1f46cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('RB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b25e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
